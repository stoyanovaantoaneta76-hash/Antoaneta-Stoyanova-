# Advanced Training Configuration with Custom Parameters
# This example demonstrates all available configuration options

[api]
adaptive_api_key = "${ADAPTIVE_API_KEY}"
base_url = "https://api.llmadaptive.uk/v1"

[dataset]
path = "train/examples/datasets/minimal_qa.csv"
type = "csv"
input_column = "input"
expected_column = "expected_output"

# Multiple models with mixed pricing strategies
[[models]]
provider = "openai"
model_name = "gpt-4"
cost_per_1m_input_tokens = 30.0
cost_per_1m_output_tokens = 60.0

[[models]]
provider = "openai"
model_name = "gpt-3.5-turbo"
# Will fetch from API

[[models]]
provider = "anthropic"
model_name = "claude-3-5-sonnet-20241022"
cost_per_1m_input_tokens = 3.0
cost_per_1m_output_tokens = 15.0

[[models]]
provider = "deepseek"
model_name = "deepseek-chat"
# Will fetch from API

# Provider configurations with custom settings
[providers.openai]
api_key = "${OPENAI_API_KEY}"
base_url = "https://api.openai.com/v1"  # Custom endpoint if needed
timeout = 90.0
max_retries = 5

[providers.anthropic]
api_key = "${ANTHROPIC_API_KEY}"
timeout = 120.0
max_retries = 3

[providers.deepseek]
api_key = "${DEEPSEEK_API_KEY}"
timeout = 60.0

# Advanced training parameters
[training]
n_clusters = 30  # More clusters for finer-grained routing
max_parallel = 20  # Higher parallelism for faster training
embedding_model = "sentence-transformers/all-MiniLM-L6-v2"
tfidf_max_features = 10000  # More TF-IDF features
tfidf_ngram_range = [1, 3]  # Include trigrams
random_seed = 12345

# Output configuration
[output]
path = "profile_custom.json"
storage_type = "local"
